name: Security Review (Example)

# This is an EXAMPLE workflow showing how to use gemini-code-security-review.
# Copy this to YOUR repository's .github/workflows/ directory.
#
# Configuration via GitHub Repository Variables & Secrets
# (Settings > Secrets and variables > Actions)
#
# --- Gemini (cloud) ---
# Secrets : GEMINI_API_KEY
# Variables: GEMINI_MODEL (optional, e.g. gemini-2.5-pro)
#
# --- Local LLM (vLLM / Ollama / LM Studio) ---
# Variables: LLM_PROVIDER        (e.g. vllm, ollama, lmstudio)
#            LOCAL_LLM_MODEL     (e.g. mistral, llama3.2)
#            LOCAL_LLM_BASE_URL  (e.g. http://your-vllm-host:8000)
# Secrets : LOCAL_LLM_API_KEY   (Bearer token â€” required for vLLM with --api-key)
#
# --- Common (optional) ---
# Variables: GEMINICLI_TIMEOUT   (minutes, default 20)
#            EXCLUDE_DIRECTORIES (comma-separated, e.g. tests,docs)

permissions:
  pull-requests: write
  contents: read

on:
  pull_request:

jobs:
  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.sha }}
          fetch-depth: 2

      - uses: your-org/gemini-code-security-review@main
        with:
          # --- LLM provider (repository variable, defaults to 'gemini') ---
          llm-provider: ${{ vars.LLM_PROVIDER || 'gemini' }}

          # --- Gemini (used when llm-provider == 'gemini') ---
          gemini-api-key: ${{ secrets.GEMINI_API_KEY }}
          gemini-model:   ${{ vars.GEMINI_MODEL }}

          # --- Local LLM (used when llm-provider == 'vllm' / 'ollama' / 'lmstudio') ---
          local-llm-model:    ${{ vars.LOCAL_LLM_MODEL }}
          local-llm-base-url: ${{ vars.LOCAL_LLM_BASE_URL }}
          local-llm-api-key:  ${{ secrets.LOCAL_LLM_API_KEY }}

          # --- Common options ---
          comment-pr:           true
          upload-results:       true
          geminicli-timeout:    ${{ vars.GEMINICLI_TIMEOUT || '20' }}
          exclude-directories:  ${{ vars.EXCLUDE_DIRECTORIES }}
